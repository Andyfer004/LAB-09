{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5430f36a",
   "metadata": {},
   "source": [
    "# LAB 8 - Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a3bcbf",
   "metadata": {},
   "source": [
    " ## Catedrático: Alberto Suriano \n",
    "\n",
    "    ### Estudiantes: \n",
    "    - Andy Fuentes 22944\n",
    "    - Davis Roldán  22672\n",
    "    - Diederich Solís 22952\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba51a9d",
   "metadata": {},
   "source": [
    "## Tasks 1 - Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93e003",
   "metadata": {},
   "source": [
    "### 1. Diferencia entre Modelos de Markov y Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc6b5a",
   "metadata": {},
   "source": [
    "Los Modelos de Markov y los Modelos Ocultos de Markov (Hidden Markov Models, HMM) están relacionados, pero su principal diferencia es que el Modelo de Markov clásico describe un proceso donde los estados del sistema son observables directamente y la probabilidad de pasar de un estado a otro depende únicamente del estado actual (no del historial pasado). En cambio, en un HMM, los estados verdaderos del sistema no son observables de manera directa; en su lugar, se observan señales o datos que dependen de esos estados ocultos. Es decir, los HMM introducen una capa de incertidumbre adicional, porque además de modelar transiciones entre estados, también modelan cómo se generan observaciones a partir de esos estados ocultos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474c65f",
   "metadata": {},
   "source": [
    "### 2. ¿Qué son los factorial HMM (Hidden Markov Models)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f596f8",
   "metadata": {},
   "source": [
    "Los Factorial Hidden Markov Models (FHMM) son una extensión de los HMM tradicionales. En un FHMM, en lugar de tener una sola cadena de estados ocultos que genera observaciones, se tienen múltiples cadenas ocultas independientes entre sí que actúan de manera conjunta para generar una única observación. Cada cadena sigue su propio proceso de Markov, pero la observación final depende de la combinación de los estados de todas las cadenas en ese momento. Esta estructura permite modelar sistemas más complejos y ricos, donde una sola cadena de estados sería insuficiente para capturar toda la dinámica del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4acefb1",
   "metadata": {},
   "source": [
    "### 3. Algoritmo Forward-Backward para HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3a1e2",
   "metadata": {},
   "source": [
    "El algoritmo Forward-Backward es un método eficiente utilizado en HMMs para calcular la probabilidad de una secuencia observada, así como para inferir la probabilidad de estar en un estado específico en un momento dado. El algoritmo tiene dos fases principales: la fase Forward, donde se recorre la secuencia de observaciones desde el inicio hacia el final acumulando las probabilidades de llegar a cada estado, y la fase Backward, donde se recorre la secuencia en sentido inverso, desde el final hacia el inicio, acumulando las probabilidades futuras desde cada estado. Finalmente, combinando ambas fases se pueden obtener las probabilidades posteriores de los estados dados los datos observados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f386182",
   "metadata": {},
   "source": [
    "### 4. ¿Por qué es necesario el paso Backward en el algoritmo Forward-Backward?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeecca4",
   "metadata": {},
   "source": [
    "El paso Backward es necesario porque en un HMM no basta con saber la probabilidad de haber llegado a un estado en el tiempo actual; también importa considerar la probabilidad de lo que falta por observar a partir de ese estado. Sin el paso Backward, sólo tendríamos información de cómo llegamos hasta un estado, pero no podríamos evaluar qué tan probable es que a partir de ese estado se generen las observaciones siguientes. Por ejemplo, supongamos que estamos analizando el comportamiento del clima, y hasta hoy el modelo sugiere que es muy probable que esté nublado. Sin embargo, si sabemos que en los próximos días hay observaciones que indican sol constante, necesitamos considerar que algunos estados \"nublados\" en el presente serían inconsistentes con la secuencia futura. El paso Backward nos ayuda a integrar esta información del futuro y ajustar nuestras inferencias de los estados ocultos de manera más precisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
